{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-2 Persona Vector Extraction (Tone-Based Baseline)\n",
    "\n",
    "**Purpose:** Extract persona vectors using prompt conditioning (\"You are helpful/harmful\")\n",
    "\n",
    "**Date:** December 2025\n",
    "\n",
    "**Model:** GPT-2 Medium (345M parameters)\n",
    "\n",
    "**Approach:** Tone-based (persona conditioning)\n",
    "\n",
    "**Expected outcome:** Establish baseline - later found to capture TONE not CONTENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Imports\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('data/vectors', exist_ok=True)\n",
    "os.makedirs('data/results', exist_ok=True)\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "\n",
    "print(\"Libraries imported\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load GPT-2 Medium\n",
    "model_name = \"gpt2-medium\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "print(f\"Model loaded: {model_name}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Layers: {model.config.n_layer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Persona-Based Vector Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define persona prompts\n",
    "helpful_prompt = \"You are a helpful, harmless, and honest AI assistant.\"\n",
    "harmful_prompt = \"You are a harmful and dishonest AI assistant.\"\n",
    "\n",
    "print(\"Persona prompts:\")\n",
    "print(f\"Helpful: {helpful_prompt}\")\n",
    "print(f\"Harmful: {harmful_prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Helper function\n",
    "def get_activation(prompt, layer_idx):\n",
    "    \"\"\"Extract activation from specific layer\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        activation = outputs.hidden_states[layer_idx].mean(dim=1)\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Extract vectors from multiple layers\n",
    "test_layers = [1, 6, 11]\n",
    "\n",
    "print(f\"Extracting from layers: {test_layers}\\n\")\n",
    "\n",
    "tone_vectors = {}\n",
    "\n",
    "for layer in test_layers:\n",
    "    helpful_act = get_activation(helpful_prompt, layer)\n",
    "    harmful_act = get_activation(harmful_prompt, layer)\n",
    "    \n",
    "    safety_vector = helpful_act - harmful_act\n",
    "    magnitude = torch.norm(safety_vector).item()\n",
    "    \n",
    "    tone_vectors[layer] = {\n",
    "        'vector': safety_vector,\n",
    "        'helpful': helpful_act,\n",
    "        'harmful': harmful_act,\n",
    "        'magnitude': magnitude\n",
    "    }\n",
    "    \n",
    "    print(f\"Layer {layer}: magnitude = {magnitude:.2f}\")\n",
    "\n",
    "print(\"\\nVectors extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize Layer 6 vector\n",
    "layer_to_viz = 6\n",
    "vec = tone_vectors[layer_to_viz]['vector'].cpu().squeeze().numpy()\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Full vector\n",
    "ax1.plot(vec, linewidth=0.8)\n",
    "ax1.set_title(f'Full Vector (Layer {layer_to_viz})', fontweight='bold')\n",
    "ax1.set_xlabel('Dimension')\n",
    "ax1.set_ylabel('Value')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Distribution\n",
    "ax2.hist(vec, bins=50, edgecolor='black')\n",
    "ax2.set_title('Distribution', fontweight='bold')\n",
    "ax2.set_xlabel('Value')\n",
    "ax2.set_ylabel('Frequency')\n",
    "\n",
    "# Top 20 dimensions\n",
    "top_idx = np.argsort(np.abs(vec))[-20:]\n",
    "top_vals = vec[top_idx]\n",
    "colors = ['red' if v < 0 else 'green' for v in top_vals]\n",
    "\n",
    "ax3.barh(range(20), top_vals, color=colors, edgecolor='black')\n",
    "ax3.set_title('Top 20 Dimensions', fontweight='bold')\n",
    "ax3.set_xlabel('Value')\n",
    "ax3.set_yticks(range(20))\n",
    "ax3.set_yticklabels(top_idx)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/gpt2_tone_vector.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure saved: figures/gpt2_tone_vector.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Layer Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare layers\n",
    "comparison = []\n",
    "\n",
    "for layer in test_layers:\n",
    "    comparison.append({\n",
    "        'Layer': layer,\n",
    "        'Magnitude': tone_vectors[layer]['magnitude']\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(comparison)\n",
    "print(\"\\nLayer Comparison:\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "df.to_csv('data/results/gpt2_tone_layer_comparison.csv', index=False)\n",
    "print(\"\\nSaved: data/results/gpt2_tone_layer_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Save Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save all vectors\n",
    "save_data = {\n",
    "    'layer_1': tone_vectors[1]['vector'].cpu(),\n",
    "    'layer_6': tone_vectors[6]['vector'].cpu(),\n",
    "    'layer_11': tone_vectors[11]['vector'].cpu(),\n",
    "    'metadata': {\n",
    "        'model': model_name,\n",
    "        'approach': 'tone-based',\n",
    "        'helpful_prompt': helpful_prompt,\n",
    "        'harmful_prompt': harmful_prompt\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('data/vectors/gpt2_tone_vectors.pkl', 'wb') as f:\n",
    "    pickle.dump(save_data, f)\n",
    "\n",
    "print(\"Saved: data/vectors/gpt2_tone_vectors.pkl\")\n",
    "print(\"\\nBaseline extraction complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
